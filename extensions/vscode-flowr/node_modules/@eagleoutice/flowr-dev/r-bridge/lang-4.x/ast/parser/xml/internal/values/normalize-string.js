"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.normalizeString = normalizeString;
const normalize_meta_1 = require("../../normalize-meta");
const assert_1 = require("../../../../../../../util/assert");
const convert_values_1 = require("../../../../../convert-values");
/**
 * Normalize the given object as a R string (see {@link string2ts}).
 * This requires you to check the corresponding name beforehand.
 *
 * @param data - The data used by the parser (see {@link NormalizerData})
 * @param obj  - The json object to extract the meta-information from
 */
function normalizeString(data, obj) {
    const { location, content } = (0, normalize_meta_1.retrieveMetaStructure)(obj);
    // based on https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/getParseData we do not get strings with 1000 characters or more within the text field.
    // therefore, we recover the full string from the surrounding expr lexeme field
    let stringContent = content;
    if (stringContent.startsWith('[')) { // something like "[9999 chars quoted with '"']"
        (0, assert_1.guard)(data.currentLexeme !== undefined, 'need current lexeme wrapper for too long strings as they are not stored by the R parser post-processor');
        stringContent = data.currentLexeme;
    }
    return {
        type: "RString" /* RType.String */,
        location,
        content: (0, convert_values_1.string2ts)(stringContent),
        lexeme: stringContent,
        info: {
            fullRange: data.currentRange,
            additionalTokens: [],
            fullLexeme: data.currentLexeme
        }
    };
}
//# sourceMappingURL=normalize-string.js.map